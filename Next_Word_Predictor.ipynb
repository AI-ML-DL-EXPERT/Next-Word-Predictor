{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPo8u1N31o19yUWjsdF1wlu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-ML-DL-EXPERT/Next-Word-Predictor/blob/main/Next_Word_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6qjGX_Nt37GZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import string\n",
        "\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_doc(filename):\n",
        "    # Open the file\n",
        "    file = open(filename, \"r\")\n",
        "\n",
        "    # Read all text\n",
        "    text = file.read()\n",
        "\n",
        "    # Close the file\n",
        "    file.close()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "aWGaWUV0pgDG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Document\n",
        "filename = \"/content/republic_clean.txt\"\n",
        "\n",
        "doc = load_doc(filename)\n",
        "\n",
        "print(doc[: 200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpf-SMWUqVUg",
        "outputId": "b6ec6891-aedd-4e0f-9bdc-e667b7903b5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï»¿BOOK I.\n",
            "\n",
            "\n",
            "I went down yesterday to the Piraeus with Glaucon the son of Ariston,\n",
            "that I might offer up my prayers to the goddess (Bendis, the Thracian\n",
            "Artemis.); and also because I wanted to see in wh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        "    # Replace \"--\" with a space \" \"\n",
        "    doc = doc.replace(\"--\", \" \")\n",
        "\n",
        "    # split into tokens by white space\n",
        "    tokens = doc.split()\n",
        "\n",
        "    # Remove punctuation from each token\n",
        "    \"\"\"The `str.maketrans(\"\", \"\", string.punctuation)` function creates a\n",
        "    translation table that can be used to remove punctuation from a string.\n",
        "     It takes three arguments: the characters to be replaced, the characters\n",
        "     to replace them with, and the characters to delete. In this case, it\n",
        "     removes all punctuation from the string.\"\"\"\n",
        "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "\n",
        "    # Remove remaining tokens that are not alphabetic\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "    # Make lower case\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "_ibWAQWSqq5b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Document\n",
        "tokens = clean_doc(doc)\n",
        "\n",
        "print(tokens[: 200])\n",
        "print(\"Total tokens: \", len(tokens))\n",
        "print(\"Unique tokens: \", len(set(tokens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crDo56DxwRTa",
        "outputId": "3eb347f6-44cf-44dc-e478-8b8ec2d7bd99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus', 'with', 'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i', 'might', 'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess', 'bendis', 'the', 'thracian', 'artemis', 'and', 'also', 'because', 'i', 'wanted', 'to', 'see', 'in', 'what', 'manner', 'they', 'would', 'celebrate', 'the', 'festival', 'which', 'was', 'a', 'new', 'thing', 'i', 'was', 'delighted', 'with', 'the', 'procession', 'of', 'the', 'inhabitants', 'but', 'that', 'of', 'the', 'thracians', 'was', 'equally', 'if', 'not', 'more', 'beautiful', 'when', 'we', 'had', 'finished', 'our', 'prayers', 'and', 'viewed', 'the', 'spectacle', 'we', 'turned', 'in', 'the', 'direction', 'of', 'the', 'city', 'and', 'at', 'that', 'instant', 'polemarchus', 'the', 'son', 'of', 'cephalus', 'chanced', 'to', 'catch', 'sight', 'of', 'us', 'from', 'a', 'distance', 'as', 'we', 'were', 'starting', 'on', 'our', 'way', 'home', 'and', 'told', 'his', 'servant', 'to', 'run', 'and', 'bid', 'us', 'wait', 'for', 'him', 'the', 'servant', 'took', 'hold', 'of', 'me', 'by', 'the', 'cloak', 'behind', 'and', 'said', 'polemarchus', 'desires', 'you', 'to', 'wait', 'i', 'turned', 'round', 'and', 'asked', 'him', 'where', 'his', 'master', 'was', 'there', 'he', 'is', 'said', 'the', 'youth', 'coming', 'after', 'you', 'if', 'you', 'will', 'only', 'wait', 'certainly', 'we', 'will', 'said', 'glaucon', 'and', 'in', 'a', 'few', 'minutes', 'polemarchus', 'appeared', 'and', 'with', 'him', 'adeimantus', 'glaucons', 'brother', 'niceratus', 'the', 'son', 'of', 'nicias', 'and', 'several', 'others', 'who', 'had', 'been', 'at', 'the', 'procession', 'polemarchus', 'said', 'to']\n",
            "Total tokens:  118683\n",
            "Unique tokens:  7409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Clean Text\n",
        "\n",
        "# Organize into sequence of tokens\n",
        "length = 50 + 1\n",
        "sequences = list()\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "    # Select sequence of tokens\n",
        "    seq = tokens[i - length: i]\n",
        "\n",
        "    # Convert into a line\n",
        "\n",
        "    line = ' '.join(seq)\n",
        "\n",
        "    # Store\n",
        "    sequences.append(line)\n",
        "\n",
        "print(\"Total sequences: \", len(sequences))\n",
        "\n",
        "sequences[: 10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gWcF46nwUSS",
        "outputId": "4e36ff96-fd9e-482b-d4be-2817a2750a89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences:  118632\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted',\n",
              " 'i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with',\n",
              " 'went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the',\n",
              " 'down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession',\n",
              " 'yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of',\n",
              " 'to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the',\n",
              " 'the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants',\n",
              " 'piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but',\n",
              " 'with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that',\n",
              " 'glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the inhabitants but that of']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokens to file, one dialog per line\n",
        "\n",
        "def save_doc(lines, filename):\n",
        "    data = \"\\n\".join(lines)\n",
        "    file = open(filename, \"w\")\n",
        "    file.write(data)\n",
        "    file.close()"
      ],
      "metadata": {
        "id": "jTRv5G-EwjX8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save sequences to file\n",
        "\n",
        "out_filename = \"/content/drive/MyDrive/Deep_Learning_Datasets/republic_sequences.txt\"\n",
        "\n",
        "save_doc(sequences, out_filename)"
      ],
      "metadata": {
        "id": "-63rjQuHCblW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Sequences"
      ],
      "metadata": {
        "id": "12smoBdmR6Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the doc into memory\n",
        "\n",
        "in_filename = \"/content/drive/MyDrive/Deep_Learning_Datasets/republic_sequences.txt\"\n",
        "\n",
        "doc = load_doc(in_filename)\n",
        "\n",
        "lines = doc.split(\"\\n\")"
      ],
      "metadata": {
        "id": "JdXdYSn8CyXg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQfDtgIYSW_g",
        "outputId": "99a1c161-c502-480f-81a2-e61d68e653f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted',\n",
              " 'i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with',\n",
              " 'went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the',\n",
              " 'down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession',\n",
              " 'yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Sequences"
      ],
      "metadata": {
        "id": "ntKJ8agsSezz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Integer encode sequences of words\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "metadata": {
        "id": "EzksqxJASY_7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igCxgWHwS2yf",
        "outputId": "9bd6634f-6990-4fd5-e976-b09f1109b922"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7410"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate into input and output\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "\n",
        "x, y = sequences[:, : -1], sequences[:, -1]\n",
        "\n",
        "y = to_categorical(y, num_classes = vocab_size)\n",
        "\n",
        "seq_length = x.shape[1]"
      ],
      "metadata": {
        "id": "weKrbE2bS5P2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0fquKMJVDG_",
        "outputId": "b03af403-d512-4da5-a002-eb35f2ef201f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118632, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJQi5GxmWS5T",
        "outputId": "d5234b46-939a-4887-b4c6-be2aeb4aa393"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118632, 7410)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit Model"
      ],
      "metadata": {
        "id": "EZ33A94GWwLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length= seq_length))\n",
        "model.add(LSTM(100, return_sequences= True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation = \"relu\"))\n",
        "model.add(Dense(vocab_size, activation = \"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R4tv2lQWywA",
        "outputId": "e1f041b0-d579-4810-ed0b-5679c479e042"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 50)            370500    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50, 100)           60400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7410)              748410    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1269810 (4.84 MB)\n",
            "Trainable params: 1269810 (4.84 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Model\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "\n",
        "history = model.fit(x, y, batch_size= 128, epochs= 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yFojoPVX4FL",
        "outputId": "a480d23a-25e3-4d46-faab-24d9ec5aab74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "116/927 [==>...........................] - ETA: 2:03 - loss: 6.7468 - accuracy: 0.0554"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "B-ygC3FzgKgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to file\n",
        "\n",
        "model.save(\"model.h5\")\n",
        "\n",
        "# Save the tokenizer\n",
        "\n",
        "pickle.dump(tokenizer, open(\"tokenizer.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "gf1wra9gYrmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "TKsDhIRWhQNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "\n",
        "loadModel_For_testing = keras.models.load_model(\"/content/model.h5\")"
      ],
      "metadata": {
        "id": "IBJqmAETgyJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "\n",
        "tokenizer = pickle.load(open(\"tokenizer.pkl\", \"rb\"))"
      ],
      "metadata": {
        "id": "CQ00W-oJhhIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Text"
      ],
      "metadata": {
        "id": "jcTxBZcHiLrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a seed text\n",
        "\n",
        "seed_text = lines[np.random.randint(0, len(lines))]\n",
        "\n",
        "print(seed_text + \"\\n\")"
      ],
      "metadata": {
        "id": "dq-y2lk8iIDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizer.texts_to_sequences([seed_text])[0]"
      ],
      "metadata": {
        "id": "jPuS81JNiqaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded"
      ],
      "metadata": {
        "id": "Gmfk-XLUkKJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Select a seed text\n",
        "text = lines[np.random.randint(0, len(lines))]\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=seq_length, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "id": "Jk5Z_Ho4j5ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYaR241EkR5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kynSxVi1sEOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnCjaXtAsoaP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}